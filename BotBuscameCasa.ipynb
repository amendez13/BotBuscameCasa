{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import smtplib, ssl\n",
    "import email\n",
    "from email.message import Message\n",
    "from email.mime.audio import MIMEAudio\n",
    "from email.mime.base import MIMEBase\n",
    "from email.mime.image import MIMEImage\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigData:\n",
    "    WEB_DRIVER_FILE_LOCATION = ''\n",
    "    NEXT_PAGE_DELAY = 0\n",
    "    NEXT_ZONE_DELAY = 0\n",
    "    listUrls = []\n",
    "    Version = \"\"\n",
    "    recipients = []\n",
    "    emailFrom = \"\"\n",
    "    sec = \"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.GetConfigData()\n",
    "\n",
    "    def GetConfigData(self):\n",
    "        if os.path.isfile( \"config.json\" ):\n",
    "            with open('config.json') as json_file:\n",
    "                data = json.load(json_file)\n",
    "            self.WEB_DRIVER_FILE_LOCATION = data['ChromeDriverLocation'] + 'chromedriver.exe'\n",
    "            self.Version = data[\"Version\"]\n",
    "            self.listUrls = data['Targets']\n",
    "            self.NEXT_PAGE_DELAY = int( data[\"NEXT_PAGE_DELAY\"] )\n",
    "            self.NEXT_ZONE_DELAY = int( data[\"NEXT_ZONE_DELAY\"] )\n",
    "            self.recipients = data['Recipients']\n",
    "            self.emailFrom = data['Sender']\n",
    "            self.sec = data['Secret']\n",
    "        else:   #default\n",
    "            self.NEXT_PAGE_DELAY = 20\n",
    "            self.NEXT_ZONE_DELAY = 120\n",
    "            self.WEB_DRIVER_FILE_LOCATION = 'C:/Users/myuser/path/to/chromedriver.exe'\n",
    "            self.listUrls = [\"https://www.idealista.com/venta-viviendas/madrid/hortaleza/apostol-santiago/\",\n",
    "                        \"https://www.idealista.com/venta-viviendas/madrid/hortaleza/pinar-del-rey/\"]\n",
    "            self.recipients = []\n",
    "            sef.emailFrom = \"example3@example.com\"\n",
    "            self.sec = \"xxx\"\n",
    "\n",
    "class DbPage:\n",
    "    idList = []\n",
    "    platformList = []\n",
    "    titleList =  []\n",
    "    priceList =  []\n",
    "    parkingList = []\n",
    "    habList = []\n",
    "    nbanosList = []\n",
    "    supList = []\n",
    "    plantaList = []\n",
    "    telefoneList =  []\n",
    "    listHrefs = []\n",
    "    listBarrio = []\n",
    "    listZona = []\n",
    "    listYear = []\n",
    "    listMonth = []\n",
    "    listDay = []\n",
    "    listActive = []\n",
    "    listYearInac = []\n",
    "    listMonthInac = []\n",
    "    listDayInac = []\n",
    "    listCaract = []\n",
    "    listComent = []\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.idList = []\n",
    "        self.platformList = []\n",
    "        self.titleList =  []\n",
    "        self.priceList =  []\n",
    "        self.parkingList = []\n",
    "        self.habList = []\n",
    "        self.nbanosList = []\n",
    "        self.supList = []\n",
    "        self.plantaList = []\n",
    "        self.telefoneList =  []\n",
    "        self.listHrefs = []\n",
    "        self.listBarrio = []\n",
    "        self.listZona = []\n",
    "        self.listYear = []\n",
    "        self.listMonth = []\n",
    "        self.listDay = []\n",
    "        self.listActive = []\n",
    "        self.listYearInac = []\n",
    "        self.listMonthInac = []\n",
    "        self.listDayInac = []\n",
    "        self.listCaract = []\n",
    "        self.listComent = []\n",
    "\n",
    "def getDf():\n",
    "    df = pd.DataFrame(columns=['IdPlat','Plat','Titulo','Precio','Hab','N_Banos','Sup','Planta','Garaje','Telefono','Url','Barrio','Zona','Year','Month', 'Day', 'Active', 'YearInact','MonthInact', 'DayInact', 'Caract', 'Comentario'])\n",
    "    df = df.astype({\"IdPlat\": int})\n",
    "    return df\n",
    "\n",
    "class DfDbContainer:\n",
    "    df_Db_in = getDf()\n",
    "    df_today = getDf()\n",
    "    df_Db_out = getDf()\n",
    "    df_new = getDf()\n",
    "    df_Inactive = getDf()\n",
    "    df_InactConf = getDf()\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.df_Db_in = getDf()\n",
    "        self.df_today = getDf()\n",
    "        self.df_Db_out = getDf()\n",
    "        self.df_new = getDf()\n",
    "        self.df_Inactive = getDf()\n",
    "        self.df_InactConf = getDf()\n",
    "        \n",
    "def setTitlePriceTelef(page, soup):\n",
    "    page.titleList = soup.select(\"div.item-info-container > a.item-link\")\n",
    "    page.priceList = soup.select(\"div.item-info-container > div.price-row > span.item-price\")\n",
    "    \n",
    "    for elem in soup.select(\"div.item-info-container > div.item-toolbar\"):\n",
    "        try:\n",
    "            page.telefoneList.append( elem.select(\"span.icon-phone\")[0].get_text() ) \n",
    "        except IndexError as error:\n",
    "            page.telefoneList.append( \"NA\" )\n",
    "\n",
    "def setIdealista(page, soup): #Encontrar id Idealista del piso\n",
    "    date =  datetime.now()\n",
    "    for elem in soup.select(\"div.item-info-container > a.item-link\"):\n",
    "        page.idList.append( int(elem[\"href\"].split(\"/\")[2]) )\n",
    "        page.platformList.append(\"idealista\")\n",
    "        page.listYear.append( date.year )\n",
    "        page.listMonth.append( date.month )\n",
    "        page.listDay.append( date.day )\n",
    "        \n",
    "def setHabSupPl(page, soup):  #Encontrar Habitaciones, superficie y planta\n",
    "    isHab = lambda a : True if \"hab\" in a else False\n",
    "    isSup = lambda a : True if \"m²\" in a else False\n",
    "    isPlanta = lambda a : True if (\"planta\".lower() in a.lower() or \"Bajo\".lower() in a.lower() or \"exterior\".lower() in a.lower() ) else False\n",
    "    set_bit = lambda value, bit : value | (1<<bit)  #zero index\n",
    "\n",
    "    for elem in soup.select(\"div.item-info-container\"):\n",
    "        auxStr = \"\"\n",
    "        bitmap = 0  # hab,sup,planta as bits 000, 101, etc\n",
    "        for subelem in elem.select(\"span.item-detail\"):\n",
    "            auxStr = subelem.get_text()\n",
    "            if isHab(auxStr):\n",
    "                page.habList.append( auxStr )\n",
    "                bitmap = set_bit(bitmap, 2)\n",
    "            if isSup(auxStr):\n",
    "                page.supList.append( auxStr )\n",
    "                bitmap = set_bit(bitmap, 1)\n",
    "            if isPlanta(auxStr):\n",
    "                page.plantaList.append( auxStr )\n",
    "                bitmap = set_bit(bitmap, 0)\n",
    "        if (bitmap & 0x1) == False:\n",
    "            page.plantaList.append( \"NA\" )\n",
    "        elif (bitmap & 0x2)>>1 == False:\n",
    "            page.supList.append( \"NA\" )\n",
    "        elif (bitmap & 0x4)>>2 == False:\n",
    "            page.habList.append( \"NA\" )\n",
    "\n",
    "def setParking(page, soup):  # Encontrar datos Garaje\n",
    "    for elem in soup.select(\"div.item-info-container > div.price-row\"):\n",
    "        auxStr = \"\"\n",
    "        parkingElem = elem.select(\"span.item-parking\")\n",
    "        if( not parkingElem):\n",
    "            auxStr += \"No Garaje \"\n",
    "        else:\n",
    "            auxStr += parkingElem[0].get_text()\n",
    "        page.parkingList.append( auxStr )\n",
    "\n",
    "def setUrl(page, soup):  #Encontrar URL\n",
    "    for elem in soup.select(\"div.item-info-container > a.item-link\"):\n",
    "        page.listHrefs.append( \"https://www.idealista.com\" + elem['href'] )\n",
    "        \n",
    "def insertPageInDf(page, df):\n",
    "    for i in range(0,len(page.titleList)-1):\n",
    "        row = [page.idList[i],\n",
    "               page.platformList[i],\n",
    "               page.titleList[i].get_text(),\n",
    "               page.priceList[i].get_text(),\n",
    "               page.habList[i],\n",
    "               'NA',\n",
    "               page.supList[i],\n",
    "               page.plantaList[i],\n",
    "               page.parkingList[i],\n",
    "               page.telefoneList[i],\n",
    "               page.listHrefs[i],\n",
    "               page.listBarrio[i],\n",
    "               page.listZona[i],\n",
    "               page.listYear[i],\n",
    "               page.listMonth[i],\n",
    "               page.listDay[i],\n",
    "               'Yes',\n",
    "               'NA',\n",
    "               'NA',\n",
    "               'NA',\n",
    "               'NA',\n",
    "               'NA'\n",
    "               ]\n",
    "        if (df.IdPlat == int(page.idList[i])).any() :  #Evaluar tambien en caso de que si el precio es distinto, actualizar\n",
    "            continue\n",
    "        df.loc[len(df)] = row\n",
    "\n",
    "def getNextPageUrl(soup, mainUrl): #compute next page URL\n",
    "    out = \"\"\n",
    "    try:\n",
    "        out = mainUrl + soup.select(\"div.pagination > ul > li.next > a\")[0][\"href\"]\n",
    "    except IndexError as error:\n",
    "        printAndLog(\"Last page in entry\")\n",
    "        out = \"Last page in entry\"\n",
    "    return out\n",
    "\n",
    "def setBarrioZona(Barrio, url, soup, page):\n",
    "    Zona = url.split('/')[-2]\n",
    "    for elem in soup.select(\"div.item-info-container > a.item-link\"):\n",
    "        page.listBarrio.append( Barrio )\n",
    "        page.listZona.append( url.split('/')[-2].capitalize() )\n",
    "\n",
    "def OpenBrowserAndFetchData(url, config):\n",
    "    #Open webpage with selenium webdriver, extract page source, and close webdriver in order to avoid scaring target website \n",
    "    #with the multiple repeated requests that webdrive does.\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.page_load_strategy = 'eager'\n",
    "    options.add_argument(\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\")\n",
    "    driver = webdriver.Chrome(r\"{}\".format(config.WEB_DRIVER_FILE_LOCATION), options=options)\n",
    "    driver.get(url)\n",
    "    content = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    #Get Beautiful Soup Html object to work with\n",
    "    soup = BeautifulSoup(content, 'html.parser')    \n",
    "    return soup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def WorkZona(df, listUrls_entry, mainUrl, config):\n",
    "    maxLoopCounts = 20\n",
    "    counter = 0\n",
    "\n",
    "    url = listUrls_entry\n",
    "    Barrio = listUrls_entry.split('/')[-3].replace('-', ' ').title()\n",
    "    \n",
    "    while url != 'Last page in entry':\n",
    "        if counter >= maxLoopCounts:\n",
    "            break\n",
    "\n",
    "        page = DbPage()\n",
    "\n",
    "        printAndLog(\"Working.. url: \" + url + \", counter: \" + str(counter))\n",
    "        soup = OpenBrowserAndFetchData(url, config)\n",
    "\n",
    "        setTitlePriceTelef(page, soup)\n",
    "        setIdealista(page, soup)\n",
    "        printAndLog(page.idList)\n",
    "        setHabSupPl(page, soup)\n",
    "        setParking(page, soup)\n",
    "        setUrl(page, soup)\n",
    "        setBarrioZona(Barrio, url, soup, page)\n",
    "        insertPageInDf(page, df)\n",
    "\n",
    "        print(df[['IdPlat', 'Titulo']])\n",
    "        url = getNextPageUrl(soup, mainUrl)\n",
    "        \n",
    "        printAndLog(\"Next Url: \" + url)\n",
    "        if url == 'Last page in entry':\n",
    "            break\n",
    "        time.sleep( config.NEXT_PAGE_DELAY ) # NEXT_PAGE_DELAY seconds delay after request\n",
    "        counter += 1\n",
    "        \n",
    "def BuildOutputDb(df_Db_in, df_today):\n",
    "    df_Db_out = pd.concat([df_Db_in,df_today]).drop_duplicates(subset = ['IdPlat'], keep='first')\n",
    "    df_Db_out = df_Db_out.reset_index(drop=True)\n",
    "    printAndLog(df_Db_out)\n",
    "    return df_Db_out\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "#Spetial functions to find new and inactive entrys\n",
    "\n",
    "def FindNewDf(df_Db_in, df_today):\n",
    "    return df_today[df_today.IdPlat.isin(df_Db_in.IdPlat)==False]\n",
    "\n",
    "def FindInactiveDf(df_Db_in, df_today):\n",
    "    df_Inactive = df_Db_in[df_Db_in.IdPlat.isin(df_today.IdPlat)==False]\n",
    "    inactiveFromDb = df_Db_in[ df_Db_in['Active'] == 'No' ]\n",
    "    return df_Inactive[df_Inactive.IdPlat.isin(inactiveFromDb.IdPlat)==False]\n",
    "\n",
    "def MarkInactiveDf(df_InactConf, df_Db_out):\n",
    "    index = df_Db_out[df_Db_out['IdPlat'].isin(df_InactConf.IdPlat)].index\n",
    "    date =  datetime.now()\n",
    "    \n",
    "    for elem in index:\n",
    "        InsertInCell(df_Db_out, elem, 'Active', \"No\")\n",
    "        InsertInCell(df_Db_out, elem, 'YearInact', date.year)\n",
    "        InsertInCell(df_Db_out, elem, 'MonthInact', date.month)\n",
    "        InsertInCell(df_Db_out, elem, 'DayInact', date.day)\n",
    "    df_InactConf.Active = 'No'\n",
    "    df_InactConf.YearInact = date.year\n",
    "    df_InactConf.MonthInact = date.month\n",
    "    df_InactConf.DayInact = date.day\n",
    "        \n",
    "def getInactConf(df_Inactive, config):\n",
    "    list = []\n",
    "    printAndLog(\"Evaluating Inactive List: \")\n",
    "    for i, elem in enumerate(df_Inactive.Url):\n",
    "        printAndLog(elem)\n",
    "        try:\n",
    "            soup = OpenBrowserAndFetchData(elem, config)\n",
    "        except:\n",
    "            time.sleep(15)\n",
    "            continue\n",
    "        try:\n",
    "            inactiveString = soup.select(\"div.deactivated-detail_container > h1\")[0].get_text().strip()\n",
    "            if inactiveString == 'Lo sentimos, este anuncio ya no está publicado':\n",
    "                list.append(i)\n",
    "                printAndLog(\"True Positive\")\n",
    "        except IndexError as error:\n",
    "            printAndLog(\"False Positive\")\n",
    "        printAndLog(\"--------\")\n",
    "        time.sleep(15)\n",
    "\n",
    "    return df_Inactive.iloc[ list ].reset_index(drop=True)\n",
    "\n",
    "def InsertInCell(df_Db_out, row, Col, Value):\n",
    "    df_Db_out.loc[df_Db_out.index[row], Col] = Value\n",
    "\n",
    "def printAndLog(string):\n",
    "    print(string)\n",
    "    logging.info(string)\n",
    "    \n",
    "def setUpLogs():\n",
    "    if not os.path.exists('RealEstateInfo.log'):\n",
    "        open('RealEstateInfo.log', 'w').close() \n",
    "    if not os.path.exists('RealEstateDebug.log'):\n",
    "        open('RealEstateDebug.log', 'w').close() \n",
    "    logging.basicConfig(filename='RealEstateInfo.log', level=logging.INFO, format='%(levelname)s-%(asctime)s: %(message)s')\n",
    "    logging.basicConfig(encoding='utf-8')\n",
    "    logging.basicConfig(filename='RealEstateDebug.log', level=logging.DEBUG, format='%(levelname)s-%(asctime)s: %(message)s')\n",
    "    logging.basicConfig(encoding='utf-8')\n",
    "    logging.info('Opening new log session')\n",
    "    logging.debug('Opening new Debug log session')\n",
    "    \n",
    "def loadDb(name):\n",
    "    #load pandas db\n",
    "    df_Db_in = getDf()\n",
    "    try:\n",
    "        df_Db_in = pd.read_csv(name, encoding='cp1252', index_col=False, keep_default_na=False)\n",
    "    except FileNotFoundError:\n",
    "        printAndLog(\"First do one round of botting, to generate initial dbPisos.csv\")\n",
    "\n",
    "    df_Db_in = df_Db_in.astype({\"IdPlat\": int})\n",
    "    printAndLog(df_Db_in)\n",
    "    return df_Db_in\n",
    "\n",
    "def executeBot(config,mainUrl):\n",
    "    currentDateTime = lambda: datetime.now().strftime(\"%Y/%m/%d/ %H:%M:%S\")\n",
    "\n",
    "    printAndLog( \"Starting job: \" + currentDateTime() )  \n",
    "    df_today = getDf()\n",
    "\n",
    "    for elem in config.listUrls:\n",
    "        printAndLog( currentDateTime() + \", Current Url: \" + elem  ) \n",
    "        WorkZona(df_today, elem, mainUrl, config)\n",
    "        printAndLog( \"Sleeping 2 min to be nice to servers: \" + str(currentDateTime())   ) \n",
    "        time.sleep( config.NEXT_ZONE_DELAY )\n",
    "        \n",
    "    return df_today\n",
    "\n",
    "def displayLoadedUrls(config):\n",
    "    printAndLog(\"List of loaded urls:\")\n",
    "    for elem in config.listUrls:\n",
    "        printAndLog(elem)\n",
    "        \n",
    "def writeResults(Dfcont):\n",
    "    if not os.path.exists('history'):\n",
    "        os.makedirs('history')\n",
    "\n",
    "    date =  datetime.now()\n",
    "\n",
    "    todaysDirName = str(date.year) + date.strftime(\"%b\") +  date.strftime('%d')\n",
    "    todaysDirNameLocation = 'history'+ '/' + todaysDirName\n",
    "\n",
    "    if not os.path.exists( todaysDirNameLocation ):\n",
    "        os.makedirs( todaysDirNameLocation )\n",
    "\n",
    "    Dfcont.df_Db_in.to_csv( todaysDirNameLocation + '/' + 'dbIn_Pisos.csv', encoding='cp1252',index=False)\n",
    "    Dfcont.df_today.to_csv( todaysDirNameLocation + '/' + 'dbToday_Pisos.csv', encoding='cp1252',index=False)\n",
    "    Dfcont.df_Db_out.to_csv( todaysDirNameLocation + '/' + 'dbOut_Pisos.csv', encoding='cp1252',index=False)\n",
    "    Dfcont.df_new.to_csv( todaysDirNameLocation + '/' + 'dbNew_Pisos.csv', encoding='cp1252',index=False)\n",
    "    Dfcont.df_Inactive.to_csv( todaysDirNameLocation + '/' + 'dbInactive_Pisos.csv', encoding='cp1252',index=False)\n",
    "    Dfcont.df_InactConf.to_csv( todaysDirNameLocation + '/' + 'dbInactiveConf_Pisos.csv', encoding='cp1252',index=False)\n",
    "\n",
    "    #os.replace(\"RealEstateInfo.log\", todaysDirNameLocation + '/RealEstateInfo.log')  #Send log to proper dir\n",
    "    \n",
    "    #Write out df to overwrite standard input file\n",
    "    Dfcont.df_Db_out.to_csv('dbPisos.csv', encoding='cp1252',index=False)\n",
    "    \n",
    "def sendEmail(df_new, config):\n",
    "    msg = MIMEMultipart()\n",
    "    msg['Subject'] = \"Nuevos pisos de Idealista\"\n",
    "    msg['From'] = config.emailFrom\n",
    "    recp= \"\"\n",
    "    for elem in config.recipients:\n",
    "        recp = recp + elem + \", \"\n",
    "    recp = recp[:-2]\n",
    "    msg['To'] = recp\n",
    "\n",
    "    html = \"\"\"\\\n",
    "    <html>\n",
    "      <head></head>\n",
    "      <body>\n",
    "        {0}\n",
    "      </body>\n",
    "    </html>\n",
    "    \"\"\".format(df_new.to_html())\n",
    "\n",
    "    part1 = MIMEText(html, 'html')\n",
    "    msg.attach(part1)\n",
    "\n",
    "    port = 465  # For SSL\n",
    "    context = ssl.create_default_context()\n",
    "    with smtplib.SMTP_SSL(\"smtp.gmail.com\", port, context=context) as server:\n",
    "        server.login(config.emailFrom, config.sec)\n",
    "        server.sendmail(msg['From'], config.recipients, msg.as_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main(Dfcont):\n",
    "    mainUrl = \"https://www.idealista.com\"\n",
    "    config = ConfigData()\n",
    "    setUpLogs()\n",
    "    displayLoadedUrls(config)\n",
    "    Dfcont.df_Db_in = loadDb('dbPisos.csv')\n",
    "    Dfcont.df_today = executeBot(config,mainUrl)\n",
    "    Dfcont.df_Db_out = BuildOutputDb(Dfcont.df_Db_in, Dfcont.df_today)\n",
    "    Dfcont.df_Db_out.to_csv('dbPisosTemp.csv', encoding='cp1252',index=False)  #Write pandas df to temp db\n",
    "    #Get new and inactive entries\n",
    "    Dfcont.df_new = FindNewDf(Dfcont.df_Db_in, Dfcont.df_today).reset_index(drop=True)\n",
    "    Dfcont.df_Inactive = FindInactiveDf(Dfcont.df_Db_in, Dfcont.df_today).reset_index(drop=True)\n",
    "    Dfcont.df_InactConf = getInactConf(Dfcont.df_Inactive, config)\n",
    "    MarkInactiveDf(Dfcont.df_InactConf, Dfcont.df_Db_out)\n",
    "    writeResults(Dfcont)\n",
    "    sendEmail(Dfcont.df_new, config)\n",
    "    os.replace(\"RealEstateInfo.log\", todaysDirNameLocation + '/RealEstateInfo.log')  #Send log to proper dir\n",
    "\n",
    "Dfcont = DfDbContainer()\n",
    "main(Dfcont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
